{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5be7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px # to plot the time series plot\n",
    "from sklearn import metrics # for the evaluation\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "import tensorflow as tf \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import datetime\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from numpy import concatenate\n",
    "from pandas import concat\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score \n",
    "\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 7)\n",
    "plt.style.use('fast')\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "np.random.seed(123) # for reproducibility\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7bfc81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Municipio', 'Año', 'Semana_Epi', 'Casos_Dengue', 'Prom_Dia_Preci',\n",
       "       'Prom_Dia_Preci_1', 'Prom_Dia_Preci_2', 'Prom_Dia_Preci_3',\n",
       "       'Prom_Dia_Preci_4', 'Prom_Dia_Preci_5', 'Prom_Dia_Preci_6',\n",
       "       'Total_Preci_Sem', 'Total_Preci_Sem_1', 'Total_Preci_Sem_2',\n",
       "       'Total_Preci_Sem_3', 'Total_Preci_Sem_4', 'Total_Preci_Sem_5',\n",
       "       'Total_Preci_Sem_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARGAR LA BASE DE DATOS\n",
    "from pandas import read_csv\n",
    "datos = read_csv('Piedecuesta_Lags.csv', encoding='latin-1', sep=\";\")\n",
    "# Dropping the id and date columns\n",
    "datos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5618e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casos_Dengue</th>\n",
       "      <th>Prom_Dia_Preci</th>\n",
       "      <th>Total_Preci_Sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6.24</td>\n",
       "      <td>43.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.11</td>\n",
       "      <td>49.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Casos_Dengue  Prom_Dia_Preci  Total_Preci_Sem\n",
       "0             8            0.00              0.0\n",
       "1             3            6.24             43.7\n",
       "2             2            7.11             49.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = datos.drop(['Municipio', 'Año', 'Semana_Epi','Prom_Dia_Preci_1', 'Prom_Dia_Preci_2', 'Prom_Dia_Preci_3',\n",
    "       'Prom_Dia_Preci_4', 'Prom_Dia_Preci_5', 'Prom_Dia_Preci_6', 'Total_Preci_Sem_1', 'Total_Preci_Sem_2',\n",
    "       'Total_Preci_Sem_3', 'Total_Preci_Sem_4', 'Total_Preci_Sem_5','Total_Preci_Sem_6'],axis=1)\n",
    "datos.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a4b7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473 203\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(datos) * 0.7)\n",
    "test_size = len(datos) - train_size\n",
    "train, test = datos.iloc[0:train_size], datos.iloc[train_size:len(datos)]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552b09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_columns = ['Prom_Dia_Preci', 'Total_Preci_Sem']\n",
    "f_transformer = MinMaxScaler(feature_range=(0, 1))\n",
    "f_transformer = f_transformer.fit(train[f_columns].to_numpy())\n",
    "train.loc[:, f_columns] = f_transformer.transform(train[f_columns].to_numpy())\n",
    "test.loc[:, f_columns] = f_transformer.transform(test[f_columns].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cdfe596",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_transformer = MinMaxScaler(feature_range=(0, 1))\n",
    "dengue_transformer = dengue_transformer.fit(train[['Casos_Dengue']])\n",
    "train['Casos_Dengue'] = dengue_transformer.transform(train[['Casos_Dengue']])\n",
    "test['Casos_Dengue'] = dengue_transformer.transform(test[['Casos_Dengue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45be1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45bcc3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463, 10, 3) (463,) (193, 10, 3) (193,)\n"
     ]
    }
   ],
   "source": [
    "time_steps = 10\n",
    "# reshape to [samples, time_steps, n_features]\n",
    "X_train, y_train = create_dataset(train, train.Casos_Dengue, time_steps)\n",
    "X_test, y_test = create_dataset(test, test.Casos_Dengue, time_steps)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a54c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import InputLayer\n",
    "\n",
    "def LSTM_model(neuronas,\n",
    "               dropout_rate,\n",
    "               num_layers,\n",
    "               activation = 'relu',\n",
    "               init_mode='uniform',\n",
    "               #optimizer='adam'\n",
    "              ):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # CAPA DE ENTRADA\n",
    "    model.add(keras.layers.InputLayer(input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    \n",
    "    \n",
    "    #CAPAS INTERMEDIAS\n",
    "    for i in range(num_layers):\n",
    "        model.add(keras.layers.LSTM(units=neuronas,\n",
    "                                    activation=activation,\n",
    "                                    return_sequences = True,\n",
    "                                    dropout=dropout_rate,\n",
    "                                    kernel_initializer=init_mode))\n",
    "        \n",
    "        \n",
    "    #CAPA DE SALIDA\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
    "    \n",
    "    #COMPILACIÓN DEL MODELO\n",
    "    model.compile(optimizer=\"adam\", loss = 'mse', metrics = ['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a347802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIPERPARÁMETROS\n",
    "\n",
    "neuronas = [50, 70, 100]\n",
    "activation = ['sigmoid','relu', 'tanh']\n",
    "init_mode = ['uniform', 'normal', 'zero']\n",
    "num_layers = [3, 5, 7]\n",
    "dropout_rate = [0.1, 0.3, 0.5]\n",
    "\n",
    "#batch_size = [40, 60, 80]\n",
    "#epochs = [10, 50, 100]\n",
    "#learning_rate = [0.1, 0.2, 0.3],\n",
    "#momentum = [0.2, 0.4, 0.5]\n",
    "\n",
    "param_grid = dict(model__neuronas=neuronas,\n",
    "                  model__activation=activation,\n",
    "                  model__init_mode=init_mode,\n",
    "                  model__dropout_rate=dropout_rate,\n",
    "                  model__num_layers=num_layers)\n",
    "                  #batch_size=batch_size,\n",
    "                  #epochs=epochs,\n",
    "                  #optimizer__learning_rate=learning_rate,\n",
    "                  #optimizer__momentum=momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "433f84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  KerasRegressor(model=LSTM_model, verbose=0)\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=model, param_distributions=param_grid, scoring='neg_mean_squared_error',\n",
    "                        n_jobs=-1, cv=5, n_iter=20, verbose=0,random_state = 123, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d25456",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e462f21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__num_layers</th>\n",
       "      <th>param_model__neuronas</th>\n",
       "      <th>param_model__init_mode</th>\n",
       "      <th>param_model__dropout_rate</th>\n",
       "      <th>param_model__activation</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_model__num_layers param_model__neuronas param_model__init_mode  \\\n",
       "0                       3                   100                uniform   \n",
       "1                       5                    50                   zero   \n",
       "2                       3                   100                 normal   \n",
       "3                       5                    50                uniform   \n",
       "4                       5                    70                uniform   \n",
       "5                       5                    50                uniform   \n",
       "6                       7                    70                uniform   \n",
       "7                       7                   100                   zero   \n",
       "8                       5                    50                 normal   \n",
       "9                       3                   100                   zero   \n",
       "\n",
       "  param_model__dropout_rate param_model__activation  mean_test_score  \\\n",
       "0                       0.5                    tanh              NaN   \n",
       "1                       0.1                 sigmoid              NaN   \n",
       "2                       0.5                    relu              NaN   \n",
       "3                       0.3                    tanh              NaN   \n",
       "4                       0.3                 sigmoid              NaN   \n",
       "5                       0.1                    tanh              NaN   \n",
       "6                       0.3                    tanh              NaN   \n",
       "7                       0.5                 sigmoid              NaN   \n",
       "8                       0.1                    relu              NaN   \n",
       "9                       0.1                 sigmoid              NaN   \n",
       "\n",
       "   std_test_score  mean_train_score  std_train_score  \n",
       "0             NaN               NaN              NaN  \n",
       "1             NaN               NaN              NaN  \n",
       "2             NaN               NaN              NaN  \n",
       "3             NaN               NaN              NaN  \n",
       "4             NaN               NaN              NaN  \n",
       "5             NaN               NaN              NaN  \n",
       "6             NaN               NaN              NaN  \n",
       "7             NaN               NaN              NaN  \n",
       "8             NaN               NaN              NaN  \n",
       "9             NaN               NaN              NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = pd.DataFrame(fitted_model.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False)\\\n",
    "    .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca4d4158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: nan using {'model__num_layers': 3, 'model__neuronas': 100, 'model__init_mode': 'uniform', 'model__dropout_rate': 0.5, 'model__activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (fitted_model.best_score_, fitted_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef9159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
